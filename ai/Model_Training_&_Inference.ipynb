{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzM_RwMCZksW",
        "outputId": "12e9bd2e-f1e4-435a-f4fb-f603398cddfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a perfectly clean version\n",
        "clean_yaml = \"\"\"path: /content/drive/MyDrive/coco_yolo_project/dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 22\n",
        "\n",
        "names:\n",
        "  0: person\n",
        "  1: car\n",
        "  2: bus\n",
        "  3: bicycle\n",
        "  4: motorcycle\n",
        "  5: traffic light\n",
        "  6: chair\n",
        "  7: couch\n",
        "  8: tv\n",
        "  9: cup\n",
        "  10: bottle\n",
        "  11: cell phone\n",
        "  12: book\n",
        "  13: toilet\n",
        "  14: train\n",
        "  15: umbrella\n",
        "  16: fork\n",
        "  17: spoon\n",
        "  18: microwave\n",
        "  19: stop sign\n",
        "  20: fire hydrant\n",
        "  21: bench\n",
        "\"\"\"\n",
        "\n",
        "with open(\"/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml\", \"w\") as f:\n",
        "    f.write(clean_yaml)\n",
        "\n",
        "print(\"Created clean data.yaml (no comments)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUV3Z_-GgWh6",
        "outputId": "efade676-168f-4e38-cecd-6b688c19baf3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created clean data.yaml (no comments)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and check the file\n",
        "with open(\"/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
        "    content = f.read()\n",
        "    print(\"Current data.yaml content:\")\n",
        "    print(content)\n",
        "\n",
        "    # Check if nc is present\n",
        "    if \"nc: 22\" in content:\n",
        "        print(\"Successfully added nc: 22\")\n",
        "    else:\n",
        "        print(\" nc: 22 not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0iwHm9sBT3E",
        "outputId": "e22222b6-0da9-4b20-a8a5-df62a2e96c77"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current data.yaml content:\n",
            "path: /content/drive/MyDrive/coco_yolo_project/dataset\n",
            "train: images/train\n",
            "val: images/val\n",
            "\n",
            "nc: 22\n",
            "\n",
            "names:\n",
            "  0: person\n",
            "  1: car\n",
            "  2: bus\n",
            "  3: bicycle\n",
            "  4: motorcycle\n",
            "  5: traffic light\n",
            "  6: chair\n",
            "  7: couch\n",
            "  8: tv\n",
            "  9: cup\n",
            "  10: bottle\n",
            "  11: cell phone\n",
            "  12: book\n",
            "  13: toilet\n",
            "  14: train\n",
            "  15: umbrella\n",
            "  16: fork\n",
            "  17: spoon\n",
            "  18: microwave\n",
            "  19: stop sign\n",
            "  20: fire hydrant\n",
            "  21: bench\n",
            "\n",
            "Successfully added nc: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_path = Path(\"/content/drive/MyDrive/coco_yolo_project/dataset\")\n",
        "\n",
        "# Count files\n",
        "def count_files(folder, extension=\"*.jpg\"):\n",
        "    path = dataset_path / folder\n",
        "    if path.exists():\n",
        "        return len(list(path.glob(extension)))\n",
        "    return 0\n",
        "\n",
        "print(\"Dataset Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Train images: {count_files('images/train', '*.jpg') + count_files('images/train', '*.png')}\")\n",
        "print(f\"Val images: {count_files('images/val', '*.jpg') + count_files('images/val', '*.png')}\")\n",
        "print(f\"Train labels: {count_files('labels/train', '*.txt')}\")\n",
        "print(f\"Val labels: {count_files('labels/val', '*.txt')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW_OZW6oB31F",
        "outputId": "2b80f84b-712e-4e67-fe6c-ad4eff3b3d9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Summary:\n",
            "==================================================\n",
            "Train images: 526\n",
            "Val images: 131\n",
            "Train labels: 526\n",
            "Val labels: 131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN YOLOV8 MODEL"
      ],
      "metadata": {
        "id": "ts-7-4AurW1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the YOLOv8 library\n",
        "!pip install ultralytics -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG-w-gNBos-d",
        "outputId": "896d5c57-44f9-47b4-9afb-0f7c38a82e59"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "print(\" YOLO imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"GPU available: {'YES' if torch.cuda.is_available() else 'NO'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk4rQeR0DB80",
        "outputId": "766fcf05-d9cd-4a1e-b43d-46d238eeb186"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            " YOLO imported successfully!\n",
            "PyTorch version: 2.9.0+cu126\n",
            "GPU available: YES\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a small YOLO model (fast to train)\n",
        "model = YOLO('yolov8n.pt')\n",
        "print(\"Model loaded: YOLOv8 Nano (smallest, fastest to train)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soy3yKHkDNSl",
        "outputId": "43d1a878-09c4-4515-b911-5ca0493077ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 125.1MB/s 0.0s\n",
            "Model loaded: YOLOv8 Nano (smallest, fastest to train)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check your data.yaml file\n",
        "yaml_path = \"/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml\"\n",
        "print(f\"Checking: {yaml_path}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "with open(yaml_path, 'r') as f:\n",
        "    content = f.read()\n",
        "    print(content[:500])  # Show first 500 characters\n",
        "    print(\"...\")\n",
        "\n",
        "# Count your files\n",
        "print(\"\\n Counting your files:\")\n",
        "train_img_path = \"/content/drive/MyDrive/coco_yolo_project/dataset/images/train\"\n",
        "val_img_path = \"/content/drive/MyDrive/coco_yolo_project/dataset/images/val\"\n",
        "\n",
        "train_count = len([f for f in os.listdir(train_img_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "val_count = len([f for f in os.listdir(val_img_path) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "\n",
        "print(f\"Training images: {train_count}\")\n",
        "print(f\"Validation images: {val_count}\")\n",
        "print(f\"Total images: {train_count + val_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKKvEJlXDS8n",
        "outputId": "ce53c369-0357-4de8-e6fa-a1ad7023637c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking: /content/drive/MyDrive/coco_yolo_project/dataset/data.yaml\n",
            "--------------------------------------------------\n",
            "path: /content/drive/MyDrive/coco_yolo_project/dataset\n",
            "train: images/train\n",
            "val: images/val\n",
            "\n",
            "nc: 22\n",
            "\n",
            "names:\n",
            "  0: person\n",
            "  1: car\n",
            "  2: bus\n",
            "  3: bicycle\n",
            "  4: motorcycle\n",
            "  5: traffic light\n",
            "  6: chair\n",
            "  7: couch\n",
            "  8: tv\n",
            "  9: cup\n",
            "  10: bottle\n",
            "  11: cell phone\n",
            "  12: book\n",
            "  13: toilet\n",
            "  14: train\n",
            "  15: umbrella\n",
            "  16: fork\n",
            "  17: spoon\n",
            "  18: microwave\n",
            "  19: stop sign\n",
            "  20: fire hydrant\n",
            "  21: bench\n",
            "\n",
            "...\n",
            "\n",
            " Counting your files:\n",
            "Training images: 526\n",
            "Validation images: 131\n",
            "Total images: 657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing with fixed YAML...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Quick 1-epoch test\n",
        "test_results = model.train(\n",
        "    data='/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml',\n",
        "    epochs=1,\n",
        "    imgsz=640,\n",
        "    batch=4,\n",
        "    name='test_run_fixed',\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Test completed! If no errors, your setup is ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOjS5_YuF74E",
        "outputId": "3a3f9135-68b0-4e0b-ccf2-cabfb278caa8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing with fixed YAML...\n",
            "--------------------------------------------------\n",
            "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=test_run_fixed, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/test_run_fixed, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 22.0MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    755602  ultralytics.nn.modules.head.Detect           [22, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,015,138 parameters, 3,015,122 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 104.4MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 0.4Â±0.2 MB/s, size: 155.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/coco_yolo_project/dataset/labels/train.cache... 526 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 526/526 706.9Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.0Â±0.6 ms, read: 0.4Â±0.2 MB/s, size: 180.2 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/coco_yolo_project/dataset/labels/val.cache... 131 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 131/131 164.1Kit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/test_run_fixed/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/test_run_fixed\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        1/1     0.682G      1.353      4.082      1.254         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 132/132 6.4it/s 20.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 1.3s/it 22.2s\n",
            "                   all        131       1042     0.0528      0.258     0.0848     0.0557\n",
            "\n",
            "1 epochs completed in 0.013 hours.\n",
            "Optimizer stripped from /content/runs/detect/test_run_fixed/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/test_run_fixed/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/test_run_fixed/weights/best.pt...\n",
            "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,009,938 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 17/17 9.4it/s 1.8s\n",
            "                   all        131       1042     0.0528      0.258      0.085     0.0558\n",
            "                person         79        387      0.123      0.734      0.482      0.299\n",
            "                   car         31         95     0.0785      0.558      0.326      0.183\n",
            "                   bus         10         25     0.0365       0.68     0.0373     0.0285\n",
            "               bicycle          9         20     0.0102       0.15    0.00995    0.00628\n",
            "            motorcycle         10         34     0.0402      0.206      0.024     0.0145\n",
            "         traffic light         11         27          0          0          0          0\n",
            "                 chair         26         74     0.0433      0.284     0.0351     0.0235\n",
            "                 couch         10         13      0.121      0.615      0.352      0.206\n",
            "                    tv          8         11          0          0    0.00121    0.00108\n",
            "                   cup         21         70     0.0875     0.0429     0.0245     0.0173\n",
            "                bottle         19         64     0.0736      0.219     0.0474     0.0282\n",
            "            cell phone         14         28          0          0          0          0\n",
            "                  book         17         36          0          0          0          0\n",
            "                toilet          6          8     0.0294       0.75     0.0285     0.0258\n",
            "                 train         12         14       0.15      0.214      0.209      0.141\n",
            "              umbrella          7         11     0.0274      0.182    0.00884    0.00535\n",
            "                  fork         16         34    0.00781     0.0294    0.00709    0.00559\n",
            "                 spoon         16         29    0.00831      0.103     0.0035    0.00185\n",
            "             microwave          6          6      0.181      0.167     0.0486     0.0389\n",
            "             stop sign         10         10      0.138        0.6      0.192      0.173\n",
            "          fire hydrant          6          7    0.00538      0.143    0.00517    0.00465\n",
            "                 bench         15         39          0          0     0.0281     0.0241\n",
            "Speed: 0.3ms preprocess, 3.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/test_run_fixed\u001b[0m\n",
            "Test completed! If no errors, your setup is ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAINING MODEL (50 Epochs)\")\n",
        "print(\"=\" * 60)\n",
        "results = model.train(\n",
        "    data='/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml',\n",
        "    epochs=50,          # Train for 50 epochs\n",
        "    imgsz=640,          # Image size\n",
        "    batch=16,           # Batch size\n",
        "    name='yolo_final_model',  # Model name\n",
        "    project='/content/drive/MyDrive/coco_yolo_project/runs',  # Save location\n",
        "    patience=10,        # Stop if no improvement for 10 epochs\n",
        "    save=True,          # Save model\n",
        "    save_period=10,     # Save checkpoint every 10 epochs\n",
        "    device='cuda'       # Use GPU\n",
        ")\n",
        "\n",
        "print(\"Model trained for 50 epochs!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llldHqZ1Jtct",
        "outputId": "4b957297-a0fc-4d6a-ac72-1a56212f93e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING MODEL (50 Epochs)\n",
            "============================================================\n",
            "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_final_model3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/coco_yolo_project/runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    755602  ultralytics.nn.modules.head.Detect           [22, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,015,138 parameters, 3,015,122 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 70.8Â±25.4 MB/s, size: 157.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/coco_yolo_project/dataset/labels/train.cache... 526 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 526/526 793.6Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 3.0Â±5.1 ms, read: 39.6Â±37.0 MB/s, size: 181.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/coco_yolo_project/dataset/labels/val.cache... 131 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 131/131 67.2Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      2.75G      1.276       2.02      1.217        185        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.9it/s 11.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.5s\n",
            "                   all        131       1042       0.51      0.368       0.38      0.266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      2.75G      1.223      1.822       1.18        162        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.5it/s 9.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        131       1042      0.489      0.364      0.368       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      2.75G      1.253      1.765      1.202        228        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.9it/s 11.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.4s\n",
            "                   all        131       1042      0.511      0.362      0.385      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      2.75G      1.201      1.711      1.174        249        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.6it/s 9.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.7it/s 1.3s\n",
            "                   all        131       1042      0.522      0.382       0.39      0.255\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      2.75G      1.301      1.738      1.223        171        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.8it/s 11.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.3it/s 2.2s\n",
            "                   all        131       1042      0.498      0.395      0.399      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      2.76G      1.301      1.699       1.24        191        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.8it/s 11.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.6it/s 3.1s\n",
            "                   all        131       1042      0.434      0.434      0.393      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      2.78G      1.276      1.713      1.236        189        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.4s\n",
            "                   all        131       1042      0.496       0.44       0.41      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50       2.8G      1.266      1.708      1.236        223        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.2it/s 2.2s\n",
            "                   all        131       1042      0.467       0.41      0.417       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      2.81G      1.312      1.644      1.227        188        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.5s\n",
            "                   all        131       1042      0.555      0.381      0.414      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      2.83G      1.254      1.583        1.2        139        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.5s\n",
            "                   all        131       1042      0.542      0.374      0.411      0.273\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      2.83G      1.241      1.548      1.208        204        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.4it/s 9.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.9it/s 2.6s\n",
            "                   all        131       1042      0.519      0.411      0.418      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      2.83G      1.249      1.565      1.212        200        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.3it/s 10.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.3s\n",
            "                   all        131       1042      0.517       0.41      0.423      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      2.83G      1.231       1.51      1.196        235        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.3it/s 9.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.9it/s 2.6s\n",
            "                   all        131       1042      0.533      0.394      0.408      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      2.83G      1.248      1.511      1.209        151        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.7it/s 8.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.2it/s 2.3s\n",
            "                   all        131       1042      0.521        0.4      0.418       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      2.83G      1.204      1.445       1.19        177        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.3it/s 2.2s\n",
            "                   all        131       1042      0.464      0.403        0.4      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      2.83G      1.181      1.442      1.175        218        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.6it/s 9.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.1it/s 1.2s\n",
            "                   all        131       1042      0.533      0.374      0.406      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      2.83G      1.184      1.416      1.173        188        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.9it/s 11.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        131       1042      0.515      0.358      0.406      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      2.83G      1.171      1.388      1.158        217        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.7s\n",
            "                   all        131       1042       0.49      0.417      0.431      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      2.83G      1.162      1.392      1.168        171        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 11.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.4it/s 1.5s\n",
            "                   all        131       1042      0.494        0.4      0.431      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      2.83G      1.185      1.368      1.163        192        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.8it/s 11.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.7s\n",
            "                   all        131       1042      0.557      0.391      0.435      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      2.83G      1.144      1.332      1.161        268        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 11.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.6s\n",
            "                   all        131       1042      0.474      0.428       0.43      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      2.99G      1.149      1.309      1.146        183        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 11.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.3it/s 1.5s\n",
            "                   all        131       1042      0.443      0.449       0.42      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      2.99G      1.138      1.277      1.143        201        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.9it/s 11.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.3it/s 1.5s\n",
            "                   all        131       1042      0.529      0.395      0.427       0.29\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      2.99G      1.127      1.286      1.144         91        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 10.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.1it/s 1.6s\n",
            "                   all        131       1042      0.536      0.382      0.416      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      2.99G      1.135      1.267      1.136        247        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 10.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.1it/s 1.6s\n",
            "                   all        131       1042      0.511      0.403      0.417      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      2.99G      1.115      1.256      1.128        105        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.1it/s 1.6s\n",
            "                   all        131       1042      0.539      0.407      0.428      0.289\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      2.99G      1.091      1.244      1.117        212        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 11.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.4it/s 1.5s\n",
            "                   all        131       1042      0.502      0.418      0.434      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      2.99G      1.107      1.231       1.13        164        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.9it/s 11.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.1it/s 1.6s\n",
            "                   all        131       1042      0.543      0.396      0.436      0.293\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      2.99G      1.083      1.192      1.117        220        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.2it/s 10.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.1it/s 1.6s\n",
            "                   all        131       1042      0.577      0.382      0.433      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      2.99G      1.104      1.207      1.125        221        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 11.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        131       1042      0.492      0.415      0.436      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      2.99G      1.081      1.186      1.105        241        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.9it/s 11.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.1it/s 1.6s\n",
            "                   all        131       1042       0.47      0.439      0.437      0.296\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      2.99G      1.088      1.183      1.109        172        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 10.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.6s\n",
            "                   all        131       1042        0.5      0.447      0.438      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      3.16G      1.062      1.158      1.106        243        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        131       1042      0.505      0.433      0.434      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      3.16G      1.093      1.179      1.111        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 10.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.7s\n",
            "                   all        131       1042      0.517      0.432      0.445      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      3.16G      1.071      1.157      1.103        168        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        131       1042      0.531      0.445      0.454      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      3.34G      1.072      1.148      1.105        218        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.4it/s 2.1s\n",
            "                   all        131       1042      0.508      0.436      0.442      0.291\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      3.34G       1.05      1.111      1.088        233        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.3it/s 9.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.9it/s 2.6s\n",
            "                   all        131       1042      0.492      0.429      0.443      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      3.34G       1.06      1.125      1.089        259        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.4it/s 9.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.4s\n",
            "                   all        131       1042      0.589      0.394      0.443      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      3.34G      1.032      1.121      1.097        285        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.3it/s 9.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.4s\n",
            "                   all        131       1042      0.524      0.409      0.448      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      3.34G      1.018       1.07      1.081        244        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.2it/s 10.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.4s\n",
            "                   all        131       1042       0.54      0.415      0.449        0.3\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      3.34G      1.055      1.284       1.09         98        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 2.6it/s 12.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.6it/s 1.9s\n",
            "                   all        131       1042      0.498      0.448      0.451        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      3.36G      1.037      1.196      1.079         87        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.4it/s 2.1s\n",
            "                   all        131       1042      0.617        0.4      0.445      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      3.37G      1.015      1.137      1.054        129        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.4it/s 9.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.4s\n",
            "                   all        131       1042      0.574      0.389      0.439      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      3.37G     0.9798      1.091      1.041         83        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.7it/s 8.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.2it/s 2.3s\n",
            "                   all        131       1042       0.55      0.403      0.436      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      3.37G     0.9768      1.075      1.038         83        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.7it/s 8.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 4.2it/s 1.2s\n",
            "                   all        131       1042       0.58      0.412      0.444      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      3.37G     0.9945      1.068      1.039         96        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.5it/s 1.4s\n",
            "                   all        131       1042      0.538      0.423      0.441      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      3.37G     0.9538      1.051       1.03        120        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.0it/s 11.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.7it/s 1.4s\n",
            "                   all        131       1042      0.532       0.42      0.447      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      3.37G     0.9843      1.049      1.034        101        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.2it/s 10.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.4it/s 1.5s\n",
            "                   all        131       1042       0.55       0.41      0.448      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      3.37G     0.9706      1.042      1.037         88        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.1it/s 10.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.3it/s 1.5s\n",
            "                   all        131       1042      0.578        0.4      0.449      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      3.37G     0.9623      1.058      1.033        101        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 3.2it/s 10.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        131       1042      0.604      0.389      0.448      0.297\n",
            "\n",
            "50 epochs completed in 0.192 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3/weights/best.pt...\n",
            "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,009,938 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.4s\n",
            "                   all        131       1042      0.501      0.448      0.451      0.301\n",
            "                person         79        387       0.71      0.535      0.604      0.363\n",
            "                   car         31         95       0.52        0.6      0.514      0.313\n",
            "                   bus         10         25      0.374       0.56      0.507      0.353\n",
            "               bicycle          9         20      0.387        0.2      0.239      0.143\n",
            "            motorcycle         10         34      0.696      0.404      0.434      0.176\n",
            "         traffic light         11         27      0.264      0.259      0.235      0.143\n",
            "                 chair         26         74       0.48      0.349      0.353      0.199\n",
            "                 couch         10         13      0.513      0.538      0.491      0.336\n",
            "                    tv          8         11      0.287      0.404      0.357      0.253\n",
            "                   cup         21         70       0.57      0.386      0.434      0.277\n",
            "                bottle         19         64       0.45      0.453      0.341      0.179\n",
            "            cell phone         14         28      0.744      0.208      0.443      0.326\n",
            "                  book         17         36       0.48      0.222      0.219     0.0972\n",
            "                toilet          6          8      0.706          1      0.971      0.701\n",
            "                 train         12         14      0.824      0.643      0.734      0.508\n",
            "              umbrella          7         11      0.412      0.364      0.386      0.226\n",
            "                  fork         16         34      0.311      0.206      0.223      0.153\n",
            "                 spoon         16         29       0.33      0.276      0.233      0.153\n",
            "             microwave          6          6      0.327      0.833      0.719      0.602\n",
            "             stop sign         10         10      0.599      0.896      0.861      0.733\n",
            "          fire hydrant          6          7      0.548      0.286      0.422      0.279\n",
            "                 bench         15         39      0.487      0.231      0.209      0.105\n",
            "Speed: 0.2ms preprocess, 4.0ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3\u001b[0m\n",
            "Model trained for 50 epochs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"LOADING YOUR FINAL MODEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your trained model\n",
        "model_path = \"/content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "print(f\"Model loaded: {model_path}\")\n",
        "print(f\"Model knows {len(model.names)} classes\")\n",
        "print(\"This is your FINAL model with 45.1% mAP@50\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx8knDVdQ5tp",
        "outputId": "5acee31b-9c83-4913-de5d-d6d7fc81afb5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LOADING YOUR FINAL MODEL\n",
            "============================================================\n",
            "Model loaded: /content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3/weights/best.pt\n",
            "Model knows 22 classes\n",
            "This is your FINAL model with 45.1% mAP@50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val(\n",
        "    data=\"/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml\",\n",
        "    imgsz=640,\n",
        "    conf=0.25,\n",
        "    iou=0.5,\n",
        "    plots=True,     # VERY IMPORTANT\n",
        "    save=True\n",
        ")\n",
        "\n",
        "print(\"Validation finished\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y97hIpZMcPlH",
        "outputId": "ca505d84-35b0-400d-c243-935a673bae53"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.4 ms, read: 47.6Â±28.8 MB/s, size: 202.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/coco_yolo_project/dataset/labels/val.cache... 131 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 131/131 167.3Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.4it/s 3.7s\n",
            "                   all        131       1042      0.605      0.408      0.535      0.382\n",
            "                person         79        387      0.817      0.496      0.676      0.468\n",
            "                   car         31         95      0.633      0.526      0.575      0.391\n",
            "                   bus         10         25      0.467       0.56      0.523      0.409\n",
            "               bicycle          9         20        0.5        0.2      0.364      0.246\n",
            "            motorcycle         10         34      0.786      0.324      0.562      0.293\n",
            "         traffic light         11         27      0.462      0.222      0.357      0.243\n",
            "                 chair         26         74      0.618      0.284       0.47      0.304\n",
            "                 couch         10         13      0.455      0.385      0.488      0.365\n",
            "                    tv          8         11      0.308      0.364      0.351      0.276\n",
            "                   cup         21         70      0.634      0.371      0.517      0.367\n",
            "                bottle         19         64      0.487      0.297      0.399      0.233\n",
            "            cell phone         14         28      0.714      0.179      0.462      0.414\n",
            "                  book         17         36       0.75       0.25       0.49      0.251\n",
            "                toilet          6          8        0.8          1      0.971      0.723\n",
            "                 train         12         14        0.9      0.643      0.804      0.596\n",
            "              umbrella          7         11        0.8      0.364      0.618      0.406\n",
            "                  fork         16         34        0.4      0.176       0.34      0.253\n",
            "                 spoon         16         29        0.5      0.241      0.381      0.238\n",
            "             microwave          6          6      0.455      0.833      0.752      0.637\n",
            "             stop sign         10         10      0.571        0.8      0.811      0.743\n",
            "          fire hydrant          6          7      0.667      0.286      0.477      0.344\n",
            "                 bench         15         39      0.583      0.179      0.378      0.204\n",
            "Speed: 3.7ms preprocess, 4.4ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "Validation finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load FINAL trained model\n",
        "model = YOLO(\"/content/drive/MyDrive/coco_yolo_project/runs/yolo_final_model3/weights/best.pt\")\n",
        "\n",
        "# Run validation to generate confusion matrix\n",
        "metrics = model.val(\n",
        "    data=\"/content/drive/MyDrive/coco_yolo_project/dataset/data.yaml\",\n",
        "    imgsz=640,\n",
        "    conf=0.25,\n",
        "    iou=0.5,\n",
        "    plots=True,   # THIS generates confusion matrix\n",
        "    save=True\n",
        ")\n",
        "\n",
        "print(\"Validation finished â€“ confusion matrix generated\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQxEZ2Wsc0if",
        "outputId": "54ab6ec3-49dc-4b50-cfa4-ca366de68b18"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.239 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,009,938 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 50.5Â±29.4 MB/s, size: 105.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/coco_yolo_project/dataset/labels/val.cache... 131 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 131/131 181.5Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 2.9it/s 3.1s\n",
            "                   all        131       1042      0.605      0.408      0.535      0.382\n",
            "                person         79        387      0.817      0.496      0.676      0.468\n",
            "                   car         31         95      0.633      0.526      0.575      0.391\n",
            "                   bus         10         25      0.467       0.56      0.523      0.409\n",
            "               bicycle          9         20        0.5        0.2      0.364      0.246\n",
            "            motorcycle         10         34      0.786      0.324      0.562      0.293\n",
            "         traffic light         11         27      0.462      0.222      0.357      0.243\n",
            "                 chair         26         74      0.618      0.284       0.47      0.304\n",
            "                 couch         10         13      0.455      0.385      0.488      0.365\n",
            "                    tv          8         11      0.308      0.364      0.351      0.276\n",
            "                   cup         21         70      0.634      0.371      0.517      0.367\n",
            "                bottle         19         64      0.487      0.297      0.399      0.233\n",
            "            cell phone         14         28      0.714      0.179      0.462      0.414\n",
            "                  book         17         36       0.75       0.25       0.49      0.251\n",
            "                toilet          6          8        0.8          1      0.971      0.723\n",
            "                 train         12         14        0.9      0.643      0.804      0.596\n",
            "              umbrella          7         11        0.8      0.364      0.618      0.406\n",
            "                  fork         16         34        0.4      0.176       0.34      0.253\n",
            "                 spoon         16         29        0.5      0.241      0.381      0.238\n",
            "             microwave          6          6      0.455      0.833      0.752      0.637\n",
            "             stop sign         10         10      0.571        0.8      0.811      0.743\n",
            "          fire hydrant          6          7      0.667      0.286      0.477      0.344\n",
            "                 bench         15         39      0.583      0.179      0.378      0.204\n",
            "Speed: 3.4ms preprocess, 3.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val3\u001b[0m\n",
            "Validation finished â€“ confusion matrix generated\n"
          ]
        }
      ]
    }
  ]
}